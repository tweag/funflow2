{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: WordCount\n",
    "\n",
    "In this example, we'll implement a simple pipeline which \n",
    "calculates word frequencies in a plain text document. Our\n",
    "example pipeline will make use of `pureFlow` and `ioFlow`, which \n",
    "allow us to define our pipeline's tasks in terms of Haskell functions. \n",
    "\n",
    "This example may look familiar to users of Apache Beam, which \n",
    "also includes a WordCount example https://beam.apache.org/get-started/wordcount-example/.\n",
    "\n",
    "## Imports\n",
    "\n",
    "First, we'll need to import some additional modules which will enable us to \n",
    "more easily work with text (`Data.Text`), define dictionaries/maps (`Data.Map`), perform\n",
    "regex matching (`Text.Regex.Posix`), and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ":opt no-lint\n",
    "\n",
    "{-# LANGUAGE Arrows #-}\n",
    "{-# LANGUAGE OverloadedStrings #-}\n",
    "\n",
    "import Data.List (sortBy)\n",
    "import qualified Data.Map as Map\n",
    "import Data.Ord (comparing)\n",
    "import qualified Data.Text.IO as T\n",
    "import qualified Data.Text as T\n",
    "import Text.Printf (printf)\n",
    "import Text.Regex.Posix ((=~))\n",
    "\n",
    "import Funflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Since we're opting to write our pipeline using Haskell-based Flows, we need to define the Haskell\n",
    "functions which will take care of parsing our input text and counting its words. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- | (word, n_occurences)\n",
    "type TextCount = (T.Text, Int)\n",
    "\n",
    "-- | Counts members in a list of text. Also works for lazy lists (e.g. data from readFile)\n",
    "countWords :: [T.Text] -> [TextCount]\n",
    "countWords ws = let\n",
    "    tally :: Map.Map T.Text Int -> T.Text -> Map.Map T.Text Int\n",
    "    tally m k = if Map.member k m \n",
    "                then Map.adjust (+1) k m\n",
    "                else Map.insert k 1 m\n",
    "    in \n",
    "        Map.toList $ foldl tally Map.empty ws\n",
    "\n",
    "-- | Removes punctuation marks from a text\n",
    "removePunctuation :: T.Text -> T.Text\n",
    "removePunctuation = \n",
    "    let\n",
    "        punctuation = \",.?!:;\\\"\\'\" :: String\n",
    "      in T.filter (not . (`elem` punctuation))\n",
    "\n",
    "\n",
    "-- | Filters words which are not comprised of latin characters (hyphens are allowed)\n",
    "filterWords :: [T.Text] -> [T.Text]\n",
    "filterWords = \n",
    "    let \n",
    "        wordsRegex = \"[A-Za-z\\']+\" :: String\n",
    "      in filter $ (=~ wordsRegex) . T.unpack\n",
    "\n",
    "-- | Sorts a list of word counts in descending order\n",
    "sortCountsDesc :: [TextCount] -> [TextCount]\n",
    "sortCountsDesc = sortBy (flip $ comparing snd)\n",
    "\n",
    "-- | Like countWords, but with sorted results\n",
    "countWordsSortedDesc :: [T.Text] -> [TextCount]\n",
    "countWordsSortedDesc = sortCountsDesc . countWords\n",
    "\n",
    "-- | Prepare word counts for printing\n",
    "formatCounts :: [TextCount] -> [T.Text]\n",
    "formatCounts = map (\\(w,c) -> T.pack $ printf \"%s: %d\" (T.unpack w) c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Definition\n",
    "\n",
    "With our core utility functions defined, we're ready to define our pipeline. One \n",
    "simple way to structure our pipeline is to divide it into three tasks/operations:\n",
    "\n",
    "1. Read the input text file \n",
    "2. Parse the input text and return a summary of the word frequencies in it \n",
    "3. Write out our results. For this example, we can just write them directly to the terminal.\n",
    "\n",
    "Remember that in `funflow`, we create `flows` containing one or more `tasks` and combine them \n",
    "into a final, larger `Flow` DAG. This is different than how DAGs are constructed in other workflow \n",
    "frameworks like Apache Airflow, where the _tasks_ are what get composed together. The advantage\n",
    "of making entire `Flow` DAGs composable is that you can share and re-use entire subsections of your workflow \n",
    "instead of only being able to re-use individual tasks.\n",
    "\n",
    "For example, say that you write a `flow` which contains some complex branching logic for reporting errors\n",
    "based on its input values (e.g. send a Slack message to the dev team if an upstream task reports an error). \n",
    "With `funflow`, you can simply re-use that `Flow` across all of your various workflows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Individual task definitions (remember that each task is also a full \"Flow\")\n",
    "readDocument :: Flow String T.Text\n",
    "readDocument = ioFlow T.readFile\n",
    "\n",
    "countWordsAndSummarize :: Flow T.Text T.Text\n",
    "countWordsAndSummarize = pureFlow $ (T.unlines . formatCounts . countWordsSortedDesc . filterWords. T.words . removePunctuation)\n",
    "\n",
    "writeResult :: Flow (String, T.Text) ()\n",
    "writeResult = let\n",
    "        writeOutputMessage :: (String, T.Text) -> IO ()\n",
    "        writeOutputMessage (f, countText) = do\n",
    "            T.putStrLn \"Normally we would write the result to a file with T.writeFile, but for this example we can instead print the output:\"\n",
    "            T.putStrLn countText \n",
    "            return ()\n",
    "    in ioFlow writeOutputMessage\n",
    "\n",
    "-- Build the final pipeline using the task Flows defined above\n",
    "--   Note: Using arrow syntax to control which inputs get passed to\n",
    "--   which pipeline tasks, i.e. result_name <- task <- task_input\n",
    "flow :: Flow (String, String) ()\n",
    "flow = proc (documentFilePath, outputSummaryFilePath) -> do\n",
    "    documentText <- readDocument -< documentFilePath\n",
    "    countSummary <- countWordsAndSummarize -< documentText\n",
    "    writeResult -< (outputSummaryFilePath, countSummary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the pipeline\n",
    "\n",
    "And finally, with our pipeline defined, we're ready to run it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runFlow flow (\"words.txt\":: String, \"outputs/counts.txt\"::String) :: IO ()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Haskell - haskell",
   "language": "haskell",
   "name": "ihaskell_haskell"
  },
  "language_info": {
   "codemirror_mode": "Haskell",
   "file_extension": ".hs",
   "mimetype": "text/x-haskell",
   "name": "haskell",
   "pygments_lexer": "Haskell",
   "version": "8.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
